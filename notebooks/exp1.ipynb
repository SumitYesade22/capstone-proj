{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\atlas\\lib\\site-packages\\pydantic\\_internal\\_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Solid comedy entertainment, with musical inter...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>i love bad shark movies. i really do. i laugh ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>If you want to be cynical and pedantic you cou...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>1st watched 5/17/2002 - 3 out of 10(Dir-Ewald ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>This BBC series is excellent. I am no Paleonto...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentiment\n",
       "960  Solid comedy entertainment, with musical inter...  negative\n",
       "282  i love bad shark movies. i really do. i laugh ...  negative\n",
       "251  If you want to be cynical and pedantic you cou...  positive\n",
       "946  1st watched 5/17/2002 - 3 out of 10(Dir-Ewald ...  negative\n",
       "465  This BBC series is excellent. I am no Paleonto...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB.csv')\n",
    "df = df.sample(500)\n",
    "df.to_csv('data.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "# Define text preprocessing functions\n",
    "def lemmatization(text):\n",
    "    \"\"\"Lemmatize the text.\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Remove stop words from the text.\"\"\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = [word for word in str(text).split() if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    \"\"\"Remove numbers from the text.\"\"\"\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "    \"\"\"Convert text to lower case.\"\"\"\n",
    "    text = text.split()\n",
    "    text = [word.lower() for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    \"\"\"Remove punctuations from the text.\"\"\"\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = text.replace('Ø›', \"\")\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def removing_urls(text):\n",
    "    \"\"\"Remove URLs from the text.\"\"\"\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def normalize_text(df):\n",
    "    \"\"\"Normalize the text data.\"\"\"\n",
    "    try:\n",
    "        df['review'] = df['review'].apply(lower_case)\n",
    "        df['review'] = df['review'].apply(remove_stop_words)\n",
    "        df['review'] = df['review'].apply(removing_numbers)\n",
    "        df['review'] = df['review'].apply(removing_punctuations)\n",
    "        df['review'] = df['review'].apply(removing_urls)\n",
    "        df['review'] = df['review'].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error during text normalization: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>solid comedy entertainment musical interlude g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>love bad shark movie really do laugh hysterica...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>want cynical pedantic could point opening raf ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>st watched dir ewald andre dupont fairly lame ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>bbc series excellent paleontologist series giv...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentiment\n",
       "960  solid comedy entertainment musical interlude g...  negative\n",
       "282  love bad shark movie really do laugh hysterica...  negative\n",
       "251  want cynical pedantic could point opening raf ...  positive\n",
       "946  st watched dir ewald andre dupont fairly lame ...  negative\n",
       "465  bbc series excellent paleontologist series giv...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalize_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    263\n",
       "positive    237\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['sentiment'].isin(['positive','negative'])\n",
    "df = df[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>solid comedy entertainment musical interlude g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>love bad shark movie really do laugh hysterica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>want cynical pedantic could point opening raf ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>st watched dir ewald andre dupont fairly lame ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>bbc series excellent paleontologist series giv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  sentiment\n",
       "960  solid comedy entertainment musical interlude g...          0\n",
       "282  love bad shark movie really do laugh hysterica...          0\n",
       "251  want cynical pedantic could point opening raf ...          1\n",
       "946  st watched dir ewald andre dupont fairly lame ...          0\n",
       "465  bbc series excellent paleontologist series giv...          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'] = df['sentiment'].map({'positive':1, 'negative':0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=50)\n",
    "X = vectorizer.fit_transform(df['review'])\n",
    "y = df['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as sumityesade14\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as sumityesade14\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"sumityesade14/capstone-proj\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"sumityesade14/capstone-proj\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository sumityesade14/capstone-proj initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository sumityesade14/capstone-proj initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/6cb47ddfe5ef4fb993c608b1e97367e8', creation_time=1753938433336, experiment_id='0', last_update_time=1753938433336, lifecycle_stage='active', name='Logistic Regression Baseline', tags={}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/sumityesade14/capstone-proj.mlflow')\n",
    "dagshub.init(repo_owner='sumityesade14', repo_name='capstone-proj', mlflow=True)\n",
    "\n",
    "# mlflow.set_experiment(\"Logistic Regression Baseline\")\n",
    "mlflow.set_experiment(\"Logistic Regression Baseline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 11:56:01,749 - INFO - Starting MLflow run...\n",
      "2025-08-01 11:56:02,381 - INFO - Logging preprocessing parameters...\n",
      "2025-08-01 11:56:03,832 - INFO - Initializing Logistic Regression model...\n",
      "2025-08-01 11:56:03,841 - INFO - Fitting the model...\n",
      "2025-08-01 11:56:03,909 - INFO - Model training complete.\n",
      "2025-08-01 11:56:03,909 - INFO - Logging model parameters...\n",
      "2025-08-01 11:56:04,327 - INFO - Making predictions...\n",
      "2025-08-01 11:56:04,331 - INFO - Calculating evaluation metrics...\n",
      "2025-08-01 11:56:04,342 - INFO - Logging evaluation metrics...\n",
      "2025-08-01 11:56:06,374 - INFO - Saving and logging the model...\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\atlas\\lib\\site-packages\\_distutils_hack\\__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\atlas\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025-08-01 11:56:15,525 - INFO - Model training and logging completed in 13.14 seconds.\n",
      "2025-08-01 11:56:15,525 - INFO - Accuracy: 0.65\n",
      "2025-08-01 11:56:15,525 - INFO - Precision: 0.6590909090909091\n",
      "2025-08-01 11:56:15,525 - INFO - Recall: 0.5918367346938775\n",
      "2025-08-01 11:56:15,534 - INFO - F1 Score: 0.6236559139784946\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "logging.info(\"Starting MLflow run...\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        logging.info(\"Logging preprocessing parameters...\")\n",
    "        mlflow.log_param(\"vectorizer\", \"Bag of Words\")\n",
    "        mlflow.log_param(\"num_features\", 50)\n",
    "        mlflow.log_param(\"test_size\", 0.2)\n",
    "\n",
    "        logging.info(\"Initializing Logistic Regression model...\")\n",
    "        model = LogisticRegression(max_iter=1000)  # Increase max_iter to prevent non-convergence issues\n",
    "\n",
    "        logging.info(\"Fitting the model...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        logging.info(\"Model training complete.\")\n",
    "\n",
    "        logging.info(\"Logging model parameters...\")\n",
    "        mlflow.log_param(\"model\", \"Logistic Regression\")\n",
    "\n",
    "        logging.info(\"Making predictions...\")\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        logging.info(\"Calculating evaluation metrics...\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        logging.info(\"Logging evaluation metrics...\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        logging.info(\"Saving and logging the model...\")\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        # Log execution time\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Model training and logging completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        # Save and log the notebook\n",
    "        # notebook_path = \"exp1_baseline_model.ipynb\"\n",
    "        # logging.info(\"Executing Jupyter Notebook. This may take a while...\")\n",
    "        # os.system(f\"jupyter nbconvert --to notebook --execute --inplace {notebook_path}\")\n",
    "        # mlflow.log_artifact(notebook_path)\n",
    "\n",
    "        # logging.info(\"Notebook execution and logging complete.\")\n",
    "\n",
    "        # Print the results for verification\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\", exc_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "print(mlflow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow==2.8.1 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle<3 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (2.2.1)\n",
      "Requirement already satisfied: databricks-cli<1,>=0.8.7 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (0.18.0)\n",
      "Requirement already satisfied: entrypoints<1 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (0.4)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (3.1.45)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (6.0.2)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (4.25.8)\n",
      "Requirement already satisfied: pytz<2024 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (2023.4)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (2.32.4)\n",
      "Requirement already satisfied: packaging<24 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (23.2)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (6.11.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (0.5.3)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (1.16.4)\n",
      "Requirement already satisfied: docker<7,>=4.0.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (6.1.3)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (3.1.1)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (1.26.4)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (1.15.3)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (2.3.1)\n",
      "Requirement already satisfied: querystring-parser<2 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (1.2.4)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (2.0.42)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (1.7.1)\n",
      "Requirement already satisfied: pyarrow<15,>=4.0.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (14.0.2)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (3.8.2)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (3.10.3)\n",
      "Requirement already satisfied: waitress<3 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (2.1.2)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from mlflow==2.8.1) (3.1.6)\n",
      "Requirement already satisfied: Mako in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow==2.8.1) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow==2.8.1) (4.14.1)\n",
      "Requirement already satisfied: tomli in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow==2.8.1) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from click<9,>=7.0->mlflow==2.8.1) (0.4.6)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.8.1) (2.10.1)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.8.1) (3.3.1)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.8.1) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.8.1) (1.17.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.7 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from databricks-cli<1,>=0.8.7->mlflow==2.8.1) (2.5.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from docker<7,>=4.0.0->mlflow==2.8.1) (1.8.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from docker<7,>=4.0.0->mlflow==2.8.1) (311)\n",
      "Requirement already satisfied: blinker>=1.9.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from Flask<4->mlflow==2.8.1) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from Flask<4->mlflow==2.8.1) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from Flask<4->mlflow==2.8.1) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from Flask<4->mlflow==2.8.1) (3.1.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from gitpython<4,>=2.1.0->mlflow==2.8.1) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow==2.8.1) (5.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow==2.8.1) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from matplotlib<4->mlflow==2.8.1) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from matplotlib<4->mlflow==2.8.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from matplotlib<4->mlflow==2.8.1) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from matplotlib<4->mlflow==2.8.1) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from matplotlib<4->mlflow==2.8.1) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from matplotlib<4->mlflow==2.8.1) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from matplotlib<4->mlflow==2.8.1) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from pandas<3->mlflow==2.8.1) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from requests<3,>=2.17.3->mlflow==2.8.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from requests<3,>=2.17.3->mlflow==2.8.1) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from requests<3,>=2.17.3->mlflow==2.8.1) (2025.7.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from scikit-learn<2->mlflow==2.8.1) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from scikit-learn<2->mlflow==2.8.1) (3.6.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.8.1) (3.2.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install mlflow==2.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\atlas\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: mlflow 2.8.1\n",
      "Uninstalling mlflow-2.8.1:\n",
      "  Successfully uninstalled mlflow-2.8.1\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall -y mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mlflow\n",
      "Version: 2.8.1\n",
      "Summary: MLflow: A Platform for ML Development and Productionization\n",
      "Home-page: https://mlflow.org/\n",
      "Author: Databricks\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: c:\\users\\asus\\anaconda3\\envs\\atlas\\lib\\site-packages\n",
      "Requires: alembic, click, cloudpickle, databricks-cli, docker, entrypoints, Flask, gitpython, importlib-metadata, Jinja2, markdown, matplotlib, numpy, packaging, pandas, protobuf, pyarrow, pytz, pyyaml, querystring-parser, requests, scikit-learn, scipy, sqlalchemy, sqlparse, waitress\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
